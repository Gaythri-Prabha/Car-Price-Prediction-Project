# -*- coding: utf-8 -*-
"""Car_price_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Gaythri-Prabha/1dcf8dcf9351690794600b26080ccf1f/machine-learning-project.ipynb

US-Car-Pricing-Analysis

1.loading and preprocessing
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('/content/CarPrice_Assignment.csv')
df = pd.DataFrame(data)

df.info()

df.head()

df.describe()

df.duplicated().sum()

"""feature engineering and encoding"""

# Drop 'CarName' as it's no longer needed
df.drop(columns=['CarName', 'car_ID'], inplace=True)

categorical_cols = ['fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel',
                    'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem']
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

"""detecting and capping outliers"""

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('price')
plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4, 5, i)  # Adjust layout for better visibility
    sns.boxplot(y=df[col])
    plt.title(col)

plt.tight_layout()
plt.show()

def cap_outliers(df, cols):
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Cap values outside the bounds
        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('price')
cap_outliers(df, numeric_cols)

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('price')
plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4, 5, i)  # Adjust layout for better visibility
    sns.boxplot(y=df[col])
    plt.title(col)

plt.tight_layout()
plt.show()

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

"""spliting data into training and testing"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

X = df.drop(columns=['price'])
y = df['price']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

"""implementing models"""

# Initialize models
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree Regressor": DecisionTreeRegressor(random_state=42),
    "Random Forest Regressor": RandomForestRegressor(random_state=42),
    "Gradient Boosting Regressor": GradientBoostingRegressor(random_state=42),
    "Support Vector Regressor": SVR()
}

# Train and evaluate models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    results[name] = {
        "R-squared": r2_score(y_test, y_pred),
        "MSE": mean_squared_error(y_test, y_pred),
        "MAE": mean_absolute_error(y_test, y_pred)
    }

results_df = pd.DataFrame(results).T
print(results_df)

plt.figure(figsize=(10, 5))
sns.barplot(x=results_df.index, y=results_df["R-squared"], palette="viridis")
plt.xticks(rotation=30)
plt.ylabel("R-squared Score")
plt.xlabel('Models')
plt.title("Model Performance Comparison")
plt.show()

"""Five regression models were tested to predict car prices, evaluated using RÂ², Mean Squared Error (MSE), and Mean Absolute Error (MAE).

- Best Model: Random Forest Regressor (RÂ² = 0.958), explaining 95.8% of price
variance with the lowest errors (MSE: 3.28M, MAE: 1284)â€”making it the most accurate predictor.

 -Second Best: Gradient Boosting Regressor (RÂ² = 0.928), performing well but
slightly less effective than Random Forest.



ðŸ”¹ Moderate Performers:

Linear Regression & Decision Tree Regressor (RÂ² = 0.894) captured patterns but had higher errors, making them less precise.

Linear Regression struggled with non-linearity, while Decision Trees risked overfitting.

 Worst Model: Support Vector Regressor (SVR) (RÂ² = -0.099, MSE: 86.8M, MAE: 5695) completely failed, producing highly inaccurate predictions.

 Conclusion: Random Forest is the best model for predicting car prices due to its high accuracy and low error rates.

Feature Selection
"""

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
feature_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)

feature_importances = feature_importances.sort_values(ascending=False)
print(feature_importances)

plt.figure(figsize=(12, 6))
feature_importances[:10].plot(kind='bar', color='c')  # Top 10 important features
plt.xlabel("Features")
plt.ylabel("Importance Score")
plt.title("Top 10 Important Features (Random Forest)")
plt.show()

# Recursive Feature Elimination (RFE) with Linear Regression

from sklearn.feature_selection import RFE
rfe = RFE(LinearRegression(), n_features_to_select=10)
rfe.fit(X_train, y_train)

# Important features selected by RFE
selected_features = X_train.columns[rfe.support_]
print("Selected Features by RFE:", selected_features.tolist())

"""Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best parameters and model performance
print("Best Parameters:", grid_search.best_params_)
best_rf = grid_search.best_estimator_

# Evaluate tuned model
y_pred_tuned = best_rf.predict(X_test)
r2_tuned = r2_score(y_test, y_pred_tuned)
mse_tuned = mean_squared_error(y_test, y_pred_tuned)
mae_tuned = mean_absolute_error(y_test, y_pred_tuned)

print(f"Tuned Model RÂ²: {r2_tuned:.4f}, MSE: {mse_tuned:.2f}, MAE: {mae_tuned:.2f}")

